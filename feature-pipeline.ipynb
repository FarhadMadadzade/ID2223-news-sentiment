{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\farha\\anaconda3\\envs\\news-sentiment\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2TokenizerFast\n",
    "import torch\n",
    "import hopsworks\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT4Tokenizer'. \n",
      "The class this function is called from is 'GPT2TokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained('Xenova/text-embedding-ada-002')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "def get_embedding(dataset, embedding_object):\n",
    "    embeddings = []\n",
    "    for data in dataset[\"text\"]:\n",
    "        embedded_text = embedding_object.encode(data)\n",
    "        embeddings.append(embedded_text)\n",
    "\n",
    "    dataset_embedded = dataset.copy()\n",
    "    dataset_embedded[\"embeddings\"] = embeddings\n",
    "    dataset_embedded = dataset_embedded.drop(columns=[\"text\"])\n",
    "    return dataset_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_phrase_bank_df = load_data(os.path.join(\"base-data\", \"FinancialPhraseBank\", \"all-data-75-above.csv\"))\n",
    "zeroshot_train_df = load_data(os.path.join(\"base-data\", \"twitter-financial-news-sentiment\", \"sent_train.csv\"))\n",
    "zeroshot_test_df = load_data(os.path.join(\"base-data\", \"twitter-financial-news-sentiment\", \"sent_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming df1, df2, df3 are your dataframes\n",
    "df = pd.concat([financial_phrase_bank_df, zeroshot_train_df, zeroshot_test_df])\n",
    "\n",
    "# Get the count of each label\n",
    "label_counts = df['label'].value_counts()\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, stratify=df['label'])\n",
    "\n",
    "# Now, X_train and y_train contain the training data and their corresponding labels\n",
    "# X_test and y_test contain the test data and their corresponding labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check of label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "2        0.642886\n",
      "1        0.213537\n",
      "0        0.143577\n",
      "Name: count, dtype: float64\n",
      "label\n",
      "2        0.642834\n",
      "1        0.213520\n",
      "0        0.143646\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_train_df = pd.DataFrame(y_train)\n",
    "train_value_counts= y_train_df.value_counts()\n",
    "# Get the percentage of each label in the training data\n",
    "print(train_value_counts / train_value_counts.sum())\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "test_value_counts= y_test_df.value_counts()\n",
    "print(test_value_counts / test_value_counts.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>2</td>\n",
       "      <td>[791, 2883, 706, 264, 19815, 1205, 369, 95851,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>2</td>\n",
       "      <td>[41651, 2467, 47738, 483, 11, 279, 1176, 8954,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7246</th>\n",
       "      <td>2</td>\n",
       "      <td>[4438, 690, 279, 11650, 66512, 6541, 279, 6355...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>2</td>\n",
       "      <td>[37, 26919, 75967, 551, 323, 12584, 267, 84397...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1</td>\n",
       "      <td>[35982, 3105, 364, 82, 4272, 11626, 369, 279, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>2</td>\n",
       "      <td>[791, 6130, 374, 2254, 2883, 469, 51137, 75142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6675</th>\n",
       "      <td>0</td>\n",
       "      <td>[6, 47, 32370, 12, 38837, 6, 27851, 8813, 6740...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>2</td>\n",
       "      <td>[2028, 374, 1405, 330, 32132, 596, 7054, 480, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123</th>\n",
       "      <td>2</td>\n",
       "      <td>[59247, 4814, 27212, 520, 38188, 2137, 76, 273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>1</td>\n",
       "      <td>[37292, 5859, 279, 1403, 24190, 690, 1893, 264...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12307 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                         embeddings\n",
       "3010      2  [791, 2883, 706, 264, 19815, 1205, 369, 95851,...\n",
       "4845      2  [41651, 2467, 47738, 483, 11, 279, 1176, 8954,...\n",
       "7246      2  [4438, 690, 279, 11650, 66512, 6541, 279, 6355...\n",
       "1475      2  [37, 26919, 75967, 551, 323, 12584, 267, 84397...\n",
       "238       1  [35982, 3105, 364, 82, 4272, 11626, 369, 279, ...\n",
       "...     ...                                                ...\n",
       "2693      2  [791, 6130, 374, 2254, 2883, 469, 51137, 75142...\n",
       "6675      0  [6, 47, 32370, 12, 38837, 6, 27851, 8813, 6740...\n",
       "5307      2  [2028, 374, 1405, 330, 32132, 596, 7054, 480, ...\n",
       "3123      2  [59247, 4814, 27212, 520, 38188, 2137, 76, 273...\n",
       "1180      1  [37292, 5859, 279, 1403, 24190, 690, 1893, 264...\n",
       "\n",
       "[12307 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_df = pd.concat([X_train, y_train], axis=1)\n",
    "test_dataset_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "train_dataset_df_embedded = get_embedding(train_dataset_df, tokenizer)\n",
    "test_dataset_df_embedded = get_embedding(test_dataset_df, tokenizer)\n",
    "\n",
    "train_dataset_df_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/197784\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "hopsworks_project = hopsworks.login() \n",
    "fs = hopsworks_project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/197784/fs/197703/fg/324944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 12307/12307 | Elapsed Time: 00:09 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: news_sentiment_traindata_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/197784/jobs/named/news_sentiment_traindata_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x1dd242dbf40>, None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_train = fs.get_or_create_feature_group(name=\"news_sentiment_traindata\", version=1, description=\"Training data and labels for financial news sentiment prediction model\", primary_key=[\"label\", \"embeddings\"], online_enabled=True)\n",
    "fg_train.insert(train_dataset_df_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/197784/fs/197703/fg/322923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 3077/3077 | Elapsed Time: 00:05 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: news_sentiment_testdata_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/197784/jobs/named/news_sentiment_testdata_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x1dd2438a7c0>, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_test = fs.get_or_create_feature_group(name=\"news_sentiment_testdata\", version=1, description=\"Test data and labels for financial news sentiment prediction model\", primary_key=[\"label\", \"embeddings\"], online_enabled=True)\n",
    "fg_test.insert(test_dataset_df_embedded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news-sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
