{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2TokenizerFast\n",
    "import torch\n",
    "import hopsworks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_csv(file_path, file_name='sentiment.csv'):\n",
    "    sentiment_map = {\"negative\": 0, \"positive\": 1, \"neutral\": 2}\n",
    "    data = []\n",
    "\n",
    "    with open(file_path, 'r', encoding=\"latin1\") as file:\n",
    "        for line in file:\n",
    "            sentence, sentiment = line.split(\"@\")\n",
    "            sentiment = sentiment.strip()  # remove any trailing whitespace\n",
    "            data.append([sentence, sentiment_map[sentiment]])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\"text\", \"label\"])\n",
    "    df.to_csv(file_name, index=False, sep=',')\n",
    "\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "def get_embedding(dataset, embedding_object):\n",
    "    embeddings = []\n",
    "    for data in dataset[\"text\"]:\n",
    "        embedded_text = embedding_object.encode(data)\n",
    "        embeddings.append(embedded_text)\n",
    "    \n",
    "    dataset[\"embeddings\"] = embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_phrase_bank_df = load_data(os.path.join(\"base-data\", \"FinancialPhraseBank\", \"all-data-75-above.csv\"))\n",
    "zeroshot_train_df = load_data(os.path.join(\"base-data\", \"twitter-financial-news-sentiment\", \"sent_train.csv\"))\n",
    "zeroshot_valid_df = load_data(os.path.join(\"base-data\", \"twitter-financial-news-sentiment\", \"sent_valid.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 233/233 [00:00<00:00, 77.3kB/s]\n",
      "vocab.json: 100%|██████████| 2.01M/2.01M [00:00<00:00, 5.82MB/s]\n",
      "merges.txt: 100%|██████████| 917k/917k [00:00<00:00, 7.98MB/s]\n",
      "tokenizer.json: 100%|██████████| 4.23M/4.23M [00:00<00:00, 26.7MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 98.0/98.0 [00:00<00:00, 32.6kB/s]\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT4Tokenizer'. \n",
      "The class this function is called from is 'GPT2TokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained('Xenova/text-embedding-ada-002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_embedding(financial_phrase_bank_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopsworks_project = hopsworks.login() \n",
    "fs = hopsworks_project.get_feature_store()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news-sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
